{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the energy of a whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from unip.utils.energy import Calculator\n",
    "\n",
    "# define a device dict\n",
    "device_dict = {\n",
    "    \"NvidiaDev\": {'device_id': 0},\n",
    "    \"IntelDev\": {},\n",
    "    }\n",
    "calculator = Calculator(device_dict)\n",
    "\n",
    "model = models.resnet18()\n",
    "model.eval().cuda()\n",
    "example_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "@calculator.measure(times=1000)\n",
    "def inference(model, example_input):\n",
    "    model(example_input)\n",
    "\n",
    "inference(model, example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the energy of sub modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from unip.utils.energy import Calculator\n",
    "\n",
    "# define a device dict\n",
    "device_dict = {\n",
    "    \"NvidiaDev\": {'device_id': 0},\n",
    "    \"IntelDev\": {},\n",
    "    }\n",
    "calculator = Calculator(device_dict)\n",
    "\n",
    "model = models.resnet18()\n",
    "model.eval().cuda()\n",
    "\n",
    "# record the input of the layer\n",
    "def forward_hook_record_input(module, input, output):\n",
    "    setattr(module, \"input\", input[0])\n",
    "\n",
    "hook = model.layer1.register_forward_hook(forward_hook_record_input)\n",
    "example_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "model(example_input)\n",
    "hook.remove()\n",
    "\n",
    "@calculator.measure(times=100)\n",
    "def inference(model, example_input):\n",
    "    model(example_input)\n",
    "\n",
    "inference(module, torch.randn_like(module.input))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
